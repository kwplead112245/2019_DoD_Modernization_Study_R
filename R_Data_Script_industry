## R Data Script 

Industry_corpus2<- tm_map(Industry_corpus2, removeWords, stopwords("english"))
tdm.Industry<-TermDocumentMatrix(Industry_corpus2, control = list())
tdm.Industry.m<-as.matrix(tdm.Industry)
term.freq<-rowSums(tdm.Industry.m)
Industry.freq.df<-data.frame(word=names(Industry.term.freq), frequency=Industry.term.freq)
Industry.freq.df<-Industry.freq.df[order(Industry.freq.df[,2], decreasing=T),]
Industry.freq.df$word<-factor(Industry.freq.df$word, levels=unique(as.character(Industry.freq.df$word)))
ggplot(Industry.freq.df[1:20,], aes(x=word, y=frequency))+geom_bar(stat="identity", fill='darkred')+coord_flip()+theme_gdocs()+geom_text(aes(label=frequency), colour="white", hjust=1.25, size=5.0)
Industry_stopwords<-c("the", "and","from", "this", "with","are", "that", "for")
Industry_corpus2<- tm_map(Industry_corpus2, removeWords, stopwords("Industry_stopwords"))
Industry_corpus2<- tm_map(Industry_corpus2, removeWords(Industry_stopwords), stopwords("english"))
Industry_corpus2<- tm_map(Industry_corpus2, removeWords,Industry_stopwords, stopwords("english"))
Industry_corpus2<- tm_map(Industry_corpus2, removeWords, Industry_stopwords)
tdm.Industry<-TermDocumentMatrix(Industry_corpus2, control = list())
tdm.Industry.m<-as.matrix(tdm.Industry)
term.freq<-rowSums(tdm.Industry.m)
Industry.freq.df<-data.frame(word=names(Industry.term.freq), frequency=Industry.term.freq)
Industry.freq.df<-Industry.freq.df[order(Industry.freq.df[,2], decreasing=T),]
Industry.freq.df$word<-factor(Industry.freq.df$word, levels=unique(as.character(Industry.freq.df$word)))
ggplot(Industry.freq.df[1:20,], aes(x=word, y=frequency))+geom_bar(stat="identity", fill='darkred')+coord_flip()+theme_gdocs()+geom_text(aes(label=frequency), colour="white", hjust=1.25, size=5.0)
view(Industry_stopwords)
Industry_corpus2<- tm_map(Industry_corpus2, removeWords, Industry_stopwords)
Industry_corpus2<- tm_map(Industry_corpus2, removeWords, Removestopwords)
Industry_corpus2<- tm_map(Industry_corpus2, removeWords, stopwords)
Industry_corpus2<-tm_map(Industry_corpus2, removeWords, stopwords("english"))
Industry_corpus2<- tm_map(Industry_corpus2, removeWords, Industry_stopwords)
ggplot(Industry.freq.df[1:20,], aes(x=word, y=frequency))+geom_bar(stat="identity", fill='darkred')+coord_flip()+theme_gdocs()+geom_text(aes(label=frequency), colour="white", hjust=1.25, size=5.0)
tdm.Industry<-TermDocumentMatrix(Industry_corpus2, control = list())
tdm.Industry.m<-as.matrix(tdm.Industry)
term.freq<-rowSums(tdm.Industry.m)
Industry.term.freq<-rowSums(tdm.Industry.m)
Industry.freq.df<-data.frame(word=names(Industry.term.freq), frequency=Industry.term.freq)
Industry.freq.df<-Industry.freq.df[order(Industry.freq.df[,2], decreasing=T),]
Industry.freq.df$word<-factor(Industry.freq.df$word, levels=unique(as.character(Industry.freq.df$word)))
ggplot(Industry.freq.df[1:20,], aes(x=word, y=frequency))+geom_bar(stat="identity", fill='darkred')+coord_flip()+theme_gdocs()+geom_text(aes(label=frequency), colour="white", hjust=1.25, size=5.0)
findFreqTerms(tdm.Industry.m, lowfreq=500, highfreq=Inf)
tdm.Industry.m2 <- TermDocumentMatrix(Industry_corpus2)
findFreqTerms(tdm.Industry.m2, lowfreq=500, highfreq=Inf)
findAssocs(tdm.Industry.m2, "cybersecurity", .75)
findAssocs(tdm.Industry.m2, "cybersecurity", .95)
savehistory("~/Project/4-42.Rhistory")
savehistory("~/Project/4-42.Rhistory")
ggplot(Industry.freq.df[1:30,], aes(x=word, y=frequency))+geom_bar(stat="identity", fill='darkred')+coord_flip()+theme_gdocs()+geom_text(aes(label=frequency), colour="white", hjust=1.25, size=5.0)
findAssocs(tdm.Industry.m2, "security", .95)
findAssocs(tdm.Industry.m2, "information", .98)
findAssocs(tdm.Industry.m2, "system", .98)
findAssocs(tdm.Industry.m2, "system", .999)
findAssocs(tdm.Industry.m2, "system", .995)
findAssocs(tdm.Industry.m2, "cybersecurity", .99)
findAssocs(tdm.Industry.m2, "cybersecurity", .98)
findAssocs(tdm.Industry.m2, "cybersecurity", .97)
findAssocs(tdm.Industry.m2, "cybersecurity", .95)
findAssocs(tdm.Industry.m2, "improving cybersecurity", .95)
findAssocs(tdm.Industry.m2, "improving cybersecurity", .50)
findAssocs(tdm.Industry.m2, "improving cybersecurity")
findAssocs(tdm.Industry.m2, "improving cybersecurity", .25)
findAssocs(tdm.Industry.m2, "cybersecurity improving", .25)
findAssocs(tdm.Industry.m2, "cybersecurity improving", .01)
findAssocs(tdm.Industry.m2, "improving cybersecurity", .01)
findAssocs(tdm.Industry.m2, "risk", .99)
findAssocs(tdm.Industry.m2, "privacy", .99)
findAssocs(tdm.Industry.m2, "privacy", 1)
findAssocs(tdm.Industry.m2, "privacy", .999)
findAssocs(tdm.Industry.m2, "privacy", .995)
findAssocs(tdm.Industry.m2, "management", .99)
findAssocs(tdm.Industry.m2, "management", .95)
findAssocs(tdm.Industry.m2, "nist", .97)
findAssocs(tdm.Industry.m2, "control", .97)
findAssocs(tdm.Industry.m2, "standards", .98)
findAssocs(tdm.Industry.m2, "framework", .98)
findAssocs(tdm.Industry.m2, "framework", .97)
findAssocs(tdm.Industry.m2, "publication", .97)
findAssocs(tdm.Industry.m2, "organization", .97)
findAssocs(tdm.Industry.m2, "organization", 1)
findAssocs(tdm.Industry.m2, "organization", .99)
findAssocs(tdm.Industry.m2, "iot", .99)
findAssocs(tdm.Industry.m2, "iot", 1)
findAssocs(tdm.Industry.m2, "federal", 1)
findAssocs(tdm.Industry.m2, "federal", .99)
findAssocs(tdm.Industry.m2, "federal", .98)
findAssocs(tdm.Industry.m2, "federal", .97)
findAssocs(tdm.Industry.m2, "federal", .95)
findAssocs(tdm.Industry.m2, "available", .95)
findAssocs(tdm.Industry.m2, "requirements", .97)
findAssocs(tdm.Industry.m2, "common", .97)
findAssocs(tdm.Industry.m2, "common", .99)
findAssocs(tdm.Industry.m2, "common", 1)
findAssocs(tdm.Industry.m2, "common", .998)
findAssocs(tdm.Industry.m2, "authorization", .998)
findAssocs(tdm.Industry.m2, "authorization", .999)
findAssocs(tdm.Industry.m2, "official", .999)
findAssocs(tdm.Industry.m2, "official", 1)
findAssocs(tdm.Industry.m2, "official", .9999)
findAssocs(tdm.Industry.m2, "official", .99999999)
industry_dfm<-corpus_subset(Industry_corpus2)
industry_dfm<-corpus_subset(Industry)
industry<-corpus(industry)
industry<-corpus(industry_corpus)
Industry_dfm<-corpus_subset(Industry_corpus2)
dfm(Industry_dfm, dictionary = myDict)
library(dplyr)
library(tidytext)
industry_bigrams<-Industry_corpus() %>%
unnest_tokens(bigram, text, token ="ngrams", n=2)
trigram.industryTDM<-TermDocumentMatrix(text.corpus["industry_corpus2"], control = list(tokenize =TrigramTokenizer))
trigram.industryTDM<-TermDocumentMatrix(industry_corpus2, control = list(tokenize =TrigramTokenizer))
trigram.industryTDM<-TermDocumentMatrix(tdm.Industry.m2, control = list(tokenize =TrigramTokenizer))
trigram.industryTDM<-tm::TermDocumentMatrix(tdm.Industry.m2, control = list(tokenize =TrigramTokenizer))
tokenize(industry)
remove.packages("tmaptools", lib="~/R/win-library/3.5")
library("dplyr", lib.loc="~/R/win-library/3.5")
library("ggplot2", lib.loc="~/R/win-library/3.5")
library("ggthemes", lib.loc="~/R/win-library/3.5")
library("pdftools", lib.loc="~/R/win-library/3.5")
library("quanteda", lib.loc="~/R/win-library/3.5")
library("SnowballC", lib.loc="~/R/win-library/3.5")
library("stringr", lib.loc="~/R/win-library/3.5")
library("tidyverse", lib.loc="~/R/win-library/3.5")
library("tidytext", lib.loc="~/R/win-library/3.5")
library("tm", lib.loc="~/R/win-library/3.5")
remove.packages("tmap", lib="~/R/win-library/3.5")
library("corpus", lib.loc="~/R/win-library/3.5")
library("corpustools", lib.loc="~/R/win-library/3.5")
library("dplyr", lib.loc="~/R/win-library/3.5")
library("ggplot2", lib.loc="~/R/win-library/3.5")
library("ggthemes", lib.loc="~/R/win-library/3.5")
library("pdftools", lib.loc="~/R/win-library/3.5")
library("quanteda", lib.loc="~/R/win-library/3.5")
library("SnowballC", lib.loc="~/R/win-library/3.5")
library("stringr", lib.loc="~/R/win-library/3.5")
library("tibble", lib.loc="~/R/win-library/3.5")
library("tidyselect", lib.loc="~/R/win-library/3.5")
library("tidytext", lib.loc="~/R/win-library/3.5")
library("tidyverse", lib.loc="~/R/win-library/3.5")
library("tm", lib.loc="~/R/win-library/3.5")
library("tokenizers", lib.loc="~/R/win-library/3.5")
library("topicmodels", lib.loc="~/R/win-library/3.5")
tokens(industry)
as.tokens(industry)
object(industry)
as.object(industry)
quanteda::tokens(Industry_corpus2, ngrams =2)
char_tolower(Industry_corpus2, keep_acronyms = FALSE)
corpus(industry)
corpus(Industry_corpus)
corpus(Industry_corpus2)
char_tolower(Industry_corpus2)
convert.tm.to.character(Industry_corpus2)
install.packages("textreg")
library("corpus", lib.loc="~/R/win-library/3.5")
library("corpustools", lib.loc="~/R/win-library/3.5")
library("dplyr", lib.loc="~/R/win-library/3.5")
library("ggplot2", lib.loc="~/R/win-library/3.5")
library("pdftools", lib.loc="~/R/win-library/3.5")
library("quanteda", lib.loc="~/R/win-library/3.5")
library("SnowballC", lib.loc="~/R/win-library/3.5")
library("stringr", lib.loc="~/R/win-library/3.5")
library("tidyr", lib.loc="~/R/win-library/3.5")
library("tidyverse", lib.loc="~/R/win-library/3.5")
library("tidytext", lib.loc="~/R/win-library/3.5")
library("tidyselect", lib.loc="~/R/win-library/3.5")
library("tm", lib.loc="~/R/win-library/3.5")
library("topicmodels", lib.loc="~/R/win-library/3.5")
library("tokenizers", lib.loc="~/R/win-library/3.5")
library("textreg", lib.loc="~/R/win-library/3.5")
convert.tm.to.character(Industry_corpus2)
tokens(Industry_corpus2, ngrams=2)
as.tokens(Industry_corpus2)
tokens(Industry_corpus2, what =c("fasterword"), remove_numbers =TRUE, remove_punct = TRUE, remove_symbols=TRUE, remove_separators=TRUE, remove_url=FALSE, ngrams=1L, skip=0L, concatenator="_", verbose=quanteda_options("verbose"), include_docvars=True)
Industry_toks<-tokens(Industry_corpus)
install.packages("readtext")
library("corpus", lib.loc="~/R/win-library/3.5")
library("corpustools", lib.loc="~/R/win-library/3.5")
library("corpustools", lib.loc="~/R/win-library/3.5")
library("antiword", lib.loc="~/R/win-library/3.5")
library("dplyr", lib.loc="~/R/win-library/3.5")
library("dtplyr", lib.loc="~/R/win-library/3.5")
library("ggplot2", lib.loc="~/R/win-library/3.5")
library("ggthemes", lib.loc="~/R/win-library/3.5")
detach("package:ggthemes", unload=TRUE)
library("ggthemes", lib.loc="~/R/win-library/3.5")
library("quanteda", lib.loc="~/R/win-library/3.5")
library("readtext", lib.loc="~/R/win-library/3.5")
library("SentimentAnalysis", lib.loc="~/R/win-library/3.5")
library("SnowballC", lib.loc="~/R/win-library/3.5")
library("stringr", lib.loc="~/R/win-library/3.5")
library("textreg", lib.loc="~/R/win-library/3.5")
library("tibble", lib.loc="~/R/win-library/3.5")
library("tidyverse", lib.loc="~/R/win-library/3.5")
library("tidytext", lib.loc="~/R/win-library/3.5")
detach("package:tidytext", unload=TRUE)
library("tidytext", lib.loc="~/R/win-library/3.5")
library("tm", lib.loc="~/R/win-library/3.5")
library("tokenizers", lib.loc="~/R/win-library/3.5")
library("topicmodels", lib.loc="~/R/win-library/3.5")
summary(industry_corpus)
corpus(Industry_corpus)
IndustryDataFrame<- as.data.frame.character(Industry_corpus2)
IndustryDataFrame<- as.data.frame(Industry_corpus2)
Industry_toks<-tokens(Industry_dfm, ngrams=2)
view(industry_toks)
view(Industry_toks)
view(Industry_corpus2)
char_ngrams(Industry_corpus2, n=2L, skip =0L, concatenator = "_")
tokens_ngrams(Industry_toks, n = 2L, skip = 0L, concatenator = "_")
Industry_dfm2<-dfm(Industry_corpus2, tolower = TRUE, stem = TRUE, select = NULL, remove = stopwords("english"), dictionary = myDict, thesaurus = NULL, valuetype = c("glob", "regex", "fixed"), groups = NULL, verbose = quanteda_options("verbose"))
Industry_dfm2<-corpus_subset(Industry_corpus2)
Industry_dfm2<-corpus(Industry_corpus2)
Industry_dfm2<-corpus_subset(Industry_corpus2)
Industry_dfm2<-corpus(Industry_corpus2, docnames = quanteda::docnames(Industry_corpus2), docvars = quanteda::docvars(Industry_corpus2), metacorpus = quanteda::metacorpus(Industry_corpus2), compress = FALSE)
Industry_dfm2<-corpus(Industry_corpus2)
Industry_dfm2<-corpus_subset(Industry_corpus2)
Industry_dfm2<-quanteda::corpus(Industry_corpus2)
Industry_dfm2<-corpus_subset(Industry_corpus2)
Industry_dfm2<-corpus_subset(Industry_dfm2)
Industry_ngrams<-dfm(Industry_dfm2, tolower = TRUE, stem = TRUE, select = NULL, remove = stopwords("english"), dictionary = myDict, thesaurus = NULL, valuetype = c("glob", "regex", "fixed"), groups = NULL, verbose = quanteda_options("verbose"))
Industry_dfm2<-Industry_ngrams
rm(Industry_ngrams)
Industry_toks<-tokens(Industry_dfm2)
Industry_toks<-tokens(Industry_corpus2)
Industry_toks<-corpus(Industry_corpus2)
Industry_toks<-tokens(Industry_corpus2)
Industry_toks<-tokens(Industry_toks)
Industry_toks<-tokens_ngrams(Industry_toks, n = 2L, skip = 0L, skip =1L, concatenator = "_")
Industry_toks<-tokens_ngrams(Industry_toks, n = 2L, skip = 0L,)
view(Industry_toks)
industry.bigrams<-dfm(Industry_dfm2, ignoredFeatures = stopwords("english"), stem=TRUE, ngrams=2)
industry.bigrams.freq<-colSums(industry.bigrams)
industry.bigrams.freq<-sort(industry.bigrams, decreasing=TRUE)
industry.bigrams.freq<-sort(industry.bigrams)
industry.bigrams.freq<-sort(industry.bigrams.freq, decreasing=TRUE)
industry.bigrams.freq.pruned<-as.numeric()
for(i in 1:length(industry.bigrams)){if (industry.bigrams[i]>industry.bigrams.threshold){industry.bigrams.freq.pruned, industry.bigrams.freq[i]}}
industry.bigrams.freq.pruned<-as.numeric() for(i in 1:length(industry.bigrams)){if (industry.bigrams[i]>industry.bigrams.threshold){industry.bigrams.freq.pruned, industry.bigrams.freq[i]}}
industry.bigrams.freq.pruned<-as.numeric()
for(i in 1:length(industry.bigrams)){if (industry.bigrams[i]>industry.bigrams.threshold){industry.bigrams.freq.pruned, industry.bigrams.freq[i]}}
for(i in 1:length(industry.bigrams)){if (industry.bigrams[i]>industry.bigrams.threshold){industry.bigrams.freq.pruned industry.bigrams.freq[i]}}
for(i in 1:length(industry.bigrams)){
if (industry.bigrams[i]>industry.bigrams.threshold){industry.bigrams.freq.pruned industry.bigrams.freq[i]}}
industry.bigrams.freq.pruned<-as.numeric(for(i in 1:length(industry.bigrams)){
if (industry.bigrams[i]>industry.bigrams.threshold){industry.bigrams.freq.pruned industry.bigrams.freq[i]}})
view(industry.bigrams.freq.pruned)
view(industry.bigrams.freq)
view(Industry_dfm2)
industry_toks<-tokens_select(Industry_corpus2, patter = '^[A-Z', valuetype = 'regex', case_insensitive = TRUE, padding = TRUE)
industry_toks<-token(Industry_corpus2)
industry_toks<-tokens(Industry_corpus2)
Industry_corpus2<-corpus(Industry_corpus2)
industry_toks<-tokens(Industry_corpus2)
industry_toks<-tokens_select(Industry_corpus2, patter = '^[A-Z', valuetype = 'regex', case_insensitive = TRUE, padding = TRUE)
industry_toks<-tokens_select(industry_toks, patter = '^[A-Z', valuetype = 'regex', case_insensitive = TRUE, padding = TRUE)
industry_toks<-tokens_select(industry_toks, patter = '^[A-Z]', valuetype = 'regex', case_insensitive = TRUE, padding = TRUE)
head(industry_toks)
Stat_industrytoks<-textstat_collocations(industry_toks, min_count = 20, tolower = TRUE)
head(Stat_industrytoks)
Stat_industrytoks<-textstat_collocations(industry_toks, min_count = 15, tolower = TRUE)
head(industry_toks)
head(Stat_industrytoks)
Stat_industrytoks<-textstat_collocations(industry_toks, min_count = 10, tolower = TRUE)
head(Stat_industrytoks)
Stat_industrytoks<-textstat_collocations(industry_toks, min_count = 5, tolower = TRUE)
head(Stat_industrytoks, 10)
Stat_industrytoks<-textstat_collocations(industry_toks, min_count = 10, tolower = TRUE)
head(Stat_industrytoks, 10)
head(Stat_industrytoks, 10, decreasing = TRUE)
unnest_tokens(Industry_toks, text, token ="ngrams", n=2)
Industry_toks<-unnest_tokens(Industry_toks, text, token ="ngrams", n=2)
Industry_toks<-tokens_ngrams(Industry_toks, n = 2L, skip = 0L,)
Stat_industrytoks_trigrams<-textstat_collocations(industry_toks, size=3, min_count = 10, tolower = TRUE)
head(Stat_industrytoks_trigrams)
Stat_industrytoks_quadgrams<-textstat_collocations(industry_toks, size=4, min_count = 10, tolower = TRUE)
head(Stat_industrytoks_quadgrams)
remove.packages("network", lib="~/R/win-library/3.5")
remove.packages("ndjson", lib="~/R/win-library/3.5")
remove.packages("mapview", lib="~/R/win-library/3.5")
remove.packages("leaflet", lib="~/R/win-library/3.5")
remove.packages("mime", lib="~/R/win-library/3.5")
remove.packages("mime", lib="~/R/win-library/3.5")
remove.packages("viridis", lib="~/R/win-library/3.5")
remove.packages("viridisLite", lib="~/R/win-library/3.5")
library("corpus", lib.loc="~/R/win-library/3.5")
library("corpustools", lib.loc="~/R/win-library/3.5")
library("dplyr", lib.loc="~/R/win-library/3.5")
library("ggplot2", lib.loc="~/R/win-library/3.5")
library("pdftools", lib.loc="~/R/win-library/3.5")
library("plyr", lib.loc="~/R/win-library/3.5")
library("quanteda", lib.loc="~/R/win-library/3.5")
library("readtext", lib.loc="~/R/win-library/3.5")
library("SentimentAnalysis", lib.loc="~/R/win-library/3.5")
library("SnowballC", lib.loc="~/R/win-library/3.5")
library("stopwords", lib.loc="~/R/win-library/3.5")
library("stringr", lib.loc="~/R/win-library/3.5")
library("tidytext", lib.loc="~/R/win-library/3.5")
library("tidyverse", lib.loc="~/R/win-library/3.5")
library("tm", lib.loc="~/R/win-library/3.5")
library("xfun", lib.loc="~/R/win-library/3.5")
library("wordcloud", lib.loc="~/R/win-library/3.5")
ggplot(DOD.freq.df[1:20,], aes(x=word, y=frequency))+geom_bar(stat="identity", fill='darkred')+coord_flip()+theme_gdocs()+geom_text(aes(label=frequency), colour="white", hjust=1.25, size=5.0)
ggplot(freq.df[1:20,], aes(x=word, y=frequency))+geom_bar(stat="identity", fill='darkred')+coord_flip()+theme_gdocs()+geom_text(aes(label=frequency), colour="white", hjust=1.25, size=5.0)
> DOD_corpus_clean<-tm_map(DOD_corpus_clean, removeWords, stopwords("english"))
> tdm.dod<-TermDocumentMatrix(DOD_corpus_clean, control = list(weighting=weightTf))
> tdm.dod.m<-as.matrix(tdm.dod)
> term.freq<-rowSums(tdm.dod.m)
> freq.df<-data.frame(word=names(term.freq), frequency=term.freq)
> freq.df<-freq.df[order(freq.df[,2], decreasing=T),]
> freq.df$word<-factor(freq.df$word, levels=unique(as.character(freq.df$word)))
> ggplot(freq.df[1:20,], aes(x=word, y=frequency))+geom_bar(stat="identity", fill='darkred')+coord_flip()+theme_gdocs()+geom_text(aes(label=frequency), colour="white", hjust=1.25, size=5.0)
DOD_corpus_clean<-tm_map(DOD_corpus_clean, removeWords, stopwords("english"))
tdm.dod<-TermDocumentMatrix(DOD_corpus_clean, control = list(weighting=weightTf))
tdm.dod.m<-as.matrix(tdm.dod)
term.freq<-rowSums(tdm.dod.m)
freq.df<-data.frame(word=names(term.freq), frequency=term.freq)
freq.df<-freq.df[order(freq.df[,2], decreasing=T),]
freq.df$word<-factor(freq.df$word, levels=unique(as.character(freq.df$word)))
ggplot(freq.df[1:20,], aes(x=word, y=frequency))+geom_bar(stat="identity", fill='darkred')+coord_flip()+theme_gdocs()+geom_text(aes(label=frequency), colour="white", hjust=1.25, size=5.0)
industry.ngrams<-textstat_frequency(industry_toks, n=200, groups = "lang")
industry.ngrams<-textstat_frequency(industry_dfm, n=200, groups = "lang")
industry.ngrams<-textstat_frequency(Industry_dfm, n=200, groups = "lang")
industry.ngrams<-textstat_frequency(Industry_dfm2, n=200, groups = "lang")
industry.ngrams<-dfm(industry_toks)
industry.ngrams<-textstat_frequency(industry.ngrams, n=200, groups = "lang")
rm(industry.ngrams)
Industry_toks<-tokens(Industry_corpus)
Industry_toks<-corpus(Industry_corpus)
Industry_toks<-corpus(Industry_data)
Industry_toks<-quanteda::corpus(Industry_data)
industry.ngrams<-dfm(Industry_corpus2)
industry.ngrams<-textstat_frequency(industry.ngrams, n=200, groups = "lang")
industry.ngrams<-textstat_frequency(industry.ngrams, n=20, groups = "lang")
industry.ngrams<-textstat_frequency(industry.ngrams, n=20)
head(industry.ngrams)
industry.ngrams<- dfm(Industry_toks)
industry.ngrams<-textstat_frequency(industry.ngrams, n=20)
head(industry.ngrams)
industry.ngrams<-dfm(industry_toks)
industry.ngrams<-textstat_frequency(industry.ngrams, n=20)
head(industry.ngrams)
tokens(industry_toks, remove_separators = TRUE, remove_stopwords("english"))
industry.ngrams<-dfm(industry_toks)
industry.ngrams<-textstat_frequency(industry.ngrams, n=20)
head(industry.ngrams)
tokens(industry_toks, remove_separators = TRUE, remove_stopwords("my_stopwords"))
my_stopwords=c("the", "and", "for", "this", "that", "but", "", " ", "will", "shall", "can")
tokens(industry_toks, remove_separators = TRUE, remove_stopwords("my_stopwords"))
industry.ngrams<-dfm(industry_toks)
industry.ngrams<-textstat_frequency(industry.ngrams, n=20)
head(industry.ngrams)
head(industry.ngrams, 10)
head(industry.ngrams, 12)
findAssocs(tdm.dod.m2, "dod", .99)
findAssocs(tdm.dod.m2, "dod", .98)
findAssocs(tdm.dod.m2, "dod", .95)
findAssocs(tdm.dod.m2, "dod", .5)
head(industry.ngrams, 12)
head(Stat_industrytoks_trigrams)
ggplot(Industry.freq.df[1:20,], aes(x=word, y=frequency))+geom_bar(stat="identity", fill='darkred')+coord_flip()+theme_gdocs()+geom_text(aes(label=frequency), colour="white", hjust=1.25, size=5.0)
ggplot(Industry.freq.df[1:20,], aes(x=word, y=frequency))+geom_bar(stat="identity", fill='darkred')+coord_flip()+theme_gdocs()+geom_text(aes(label=frequency), colour="white", hjust=1.25, size=5.0)
data_frame(Industry.freq.df, remove_stopwords("english"))
tibble(Industry.freq.df, remove_stopwords(Industry.freq.df, words =my_stopwords))
tibble(Industry.freq.df, remove_stopwords("english", words))
tibble(Industry.freq.df, remove_stopwords(("english"), words))
tibble(Industry.freq.df, remove_stopwords("english"))
tm_map(industry_data, remove_stopwords)
ggplot(Industry.term.freq[1:20,], aes(x=word, y=frequency))+geom_bar(stat="identity", fill='darkred')+coord_flip()+theme_gdocs()+geom_text(aes(label=frequency), colour="white", hjust=1.25, size=5.0)
industry.freq.df<data.frame(Industry.freq.df, removewords, stopwords("english"))
industry.freq.df<data.frame(Industry_corpus2, removewords, stopwords("english"))
industry.freq.df<-data.frame(Industry.freq.df, removewords, stopwords("english"))
industry.df<tm_map(Industry_corpus2, removewords, stopwords("english"))
industry.df<-tm_map(Industry_corpus2, removewords, stopwords("english"))
tm_map(Industry_corpus2, removewords, stopwords("english"))
tm_map(Industry_corpus2)
Industry_corpus2<-corpus(Industry_corpus2, removewords, stopwords("english"))
Industry_corpus2<-tm_map(Industry_corpus2, removewords, stopwords("english"))
Industry_corpus<-tm_map(Industry_corpus, removewords, stopwords("english"))
detach("package:xfun", unload=TRUE)
Industry_corpus<-tm_map(Industry_corpus, removewords, stopwords("english"))
rm(Industry_corpus_clean)
Industry_corpus<-tm_map(Industry_corpus, removeWords, stopwords("english"))
Industry_corpus<-tm_map(Industry_corpus, removeWords, my_stopwords)
Industry.df<-as.data.frame(Industry_corpus)
industry.tdm<-TermDocumentMatrix(Industry_corpus)
tdm.Industry<-TermDocumentMatrix(Industry_corpus, control = list(weighting=weightTf))
ggplot(Industry.freq.df[1:20,], aes(x=word, y=frequency))+geom_bar(stat="identity", fill='darkred')+coord_flip()+theme_gdocs()+geom_text(aes(label=frequency), colour="white", hjust=1.25, size=5.0)
Industry_corpus<-tm_map(Industry_corpus, removeWords, stopwords("english"))
tdm.Industry<-TermDocumentMatrix(Industry_corpus, control = list(weighting=weightTf))
Industry_corpus<-corpus(Industry_corpus)
Industry_corpus<-sapply(corpus(Industry_corpus)
)
Industry_corpus<-sapply(corpus(Industry_corpus))
Industry_corpus<- tm_map(Industry, removePunctuation)
Industry_corpus<- tm_map(Industry, stripWhitespace)
Industry_corpus<- tm_map(Industry, tolower)
Industry_corpus<- tm_map(Industry_corpus, removeWords, stopwords("english"))
Industry_corpus<- tm_map(Industry_corpus, removeWords, my_stopwords)
Industry_corpus<- tm_map(Industry, stemDocument, language = "english")
Industry_corpus<- tm_map(Industry, removeWords, my_stopwords)
Industry_corpus<- tm_map(Industry, removeWords, stopwords("english"))
tdm.Industry<-TermDocumentMatrix(Industry, control = list())
tdm.Industry<-TermDocumentMatrix(Industry_corpus, control = list())
tdm.Industry<-TermDocumentMatrix(Industry_corpus)
tdm.Industry<-TermDocumentMatrix(Industry)
tdm.Industry<-TermDocumentMatrix(Industry.2)
tdm.Industry<-TermDocumentMatrix(Industry_corpus2)
ggplot(aes(industry.ngrams = reorder(feature, frequency), y=frequency)) + geom_point()+ coord_flip()+ labs(x=NULL, y = "Frequency")+ theme_minimal()
industry_freq<-textstat_frequency(Industry_dfm, n=5, groups = NULL)
industry_freq<-textstat_frequency(Industry.bigrams, n=5, groups = NULL)
industry_freq<-textstat_frequency(industry.bigrams, n=5, groups = NULL)
ggplot(aes(industry_freq = reorder(feature, frequency), y=frequency)) + geom_point()+ coord_flip()+ labs(x=NULL, y = "Frequency")+ theme_minimal()
industry.bigrams%>% industry_freq(n=15) %>% ggplot(aes(industry_freq = reorder(feature, frequency), y=frequency)) + geom_point()+ coord_flip()+ labs(x=NULL, y = "Frequency")+ theme_minimal()
industry_freq%>% textstat_frequency(n=15) %>% ggplot(aes(industry_freq = reorder(feature, frequency), y=frequency)) + geom_point()+ coord_flip()+ labs(x=NULL, y = "Frequency")+ theme_minimal()
industry.bigrams%>% textstat_frequency(n=15) %>% ggplot(aes(industry.bigrams = reorder(feature, frequency), y=frequency)) + geom_point()+ coord_flip()+ labs(x=NULL, y = "Frequency")+ theme_minimal()
industry.bigrams%>% textstat_frequency(n=15) %>% ggplot(aes(industry.bigrams = reorder(feature, frequency), y=frequency)) + geom_point(x)+ coord_flip()+ labs(x=NULL, y = "Frequency")+ theme_minimal()
industry.bigrams%>% textstat_frequency(n=10) %>% ggplot(aes(industry.bigrams = reorder(feature, frequency), y=frequency)) + geom_point(aes(x reorder(feature, frequency), y=fit, shape=varP))+ coord_flip()+ labs(x=NULL, y = "Frequency")+ theme_minimal()
industry_freq%>% textstat_frequency(n=15) %>% ggplot(aes(x = reorder(feature, frequency), y=frequency)) + geom_point()+ coord_flip()+ labs(x=NULL, y = "Frequency")+ theme_minimal()
industry_freq%>% textstat_frequency((industry_freq),n=15) %>% ggplot(aes(x = reorder(feature, frequency), y=frequency)) + geom_point()+ coord_flip()+ labs(x=NULL, y = "Frequency")+ theme_minimal()
industry.bigrams%>% textstat_frequency(n=15) %>% ggplot(aes(x = reorder(feature, frequency), y=frequency)) + geom_point()+ coord_flip()+ labs(x=NULL, y = "Frequency")+ theme_minimal()
DOD_collocations<-tokens_select(DOD_tokens, patttern ='[A-Z]', valuetype ='regex', case_insensitive = TRUE, padding = TRUE) %>% textstat_collocations(min_count = 100)
DOD_collocations<-tokens_select(DOD_tokens, patttern ="[A-Z]", valuetype ="regex", case_insensitive = TRUE, padding = TRUE) %>% textstat_collocations(min_count = 100)
DOD_toks<-tokens(DOD_tokens)
DOD_collocations<-tokens_select(DOD_toks, patttern ='[A-Z]', valuetype ='regex', case_insensitive = TRUE, padding = TRUE) %>% textstat_collocations(min_count = 100)
DOD_collocations<-tokens_select(DOD_toks, patttern ='^[A-Z]', valuetype ='regex', case_insensitive = TRUE, padding = TRUE) %>% textstat_collocations(min_count = 100)
DOD_collocations<-tokens_select(DOD_toks, valuetype ='regex', case_insensitive = TRUE, padding = TRUE) %>% textstat_collocations(min_count = 100)
head(DOD_collocations)
head(DOD_collocations, 20)
dod_ngrams<-dfm(DOD_toks)
dod_ngrams<-textstat_frequency(dod_ngrams, n=200, groups = "lang")
dod_ngrams<-textstat_frequency(dod_ngrams, n=200)
head(dod_ngrams, 20)
tokens_select(DOD_toks, pattern =('en'), selection ='remove')
DOD_toks<-tokens_remove(DOD_toks, pattern =stopwords_en)
dod_ngrams<-dfm(DOD_toks)
dod_ngrams<-textstat_frequency(dod_ngrams, n=200)
head(dod_ngrams, 20)
DOD_toks<-tokens_remove(DOD_toks, pattern = numbers)
DOD_toks<-tokens_remove(DOD_toks, pattern = "numbers")
dod_ngrams<-dfm(DOD_toks)
dod_ngrams<-textstat_frequency(dod_ngrams, n=200)
head(dod_ngrams, 20)
DOD_trigrams<-textstat_collocations(DOD_toks, size=3, min_count = 10, tolower = TRUE)
head(DOD_trigrams, 6)
DOD_toks<-tokens(DOD_toks, what =c("word", "sentence", "character", "fastestword"), remove_numbers = TRUE)
DOD_trigrams<-textstat_collocations(DOD_toks, size=3, min_count = 10, tolower = TRUE)
DOD_ngrams<-textstat_collocations(DOD_toks, size=1, min_count = 10, tolower = TRUE)
DOD_bigrams<-textstat_collocations(DOD_toks, size=2, min_count = 10, tolower = TRUE)
head(DOD_bigrams, 10)
DOD_dict<-dfm(DOD_toks, tolower = TRUE, stem = TRUE, select = NULL, remove = stopwords("english"), dictionary = myDict, thesaurus = NULL, valuetype = c("glob", "regex", "fixed"), groups = NULL, verbose = quanteda_options("verbose"))
head(DOD_dict)
DOD_dict<-dfm(DOD_toks, dictionary = myDict)
head(DOD_dict)
DOD_dict<-dfm(DOD_tokens, dictionary = myDict)
head(DOD_dict)
head(DOD_dict, 23)
head(DOD_dict)
view(DOD_dict, 23)
view(DOD_dict)
view(DOD_dict, 15)
head(DOD_dict, 15)
head(DOD_dict, 23)
head(DOD_dict, 22)
head(DOD_dict, 21)
head(DOD_dict, 20)
known_threats<-corpus(VectorSource(~/Project))
library(shiny)
vars=names(DOD, Industry)
Combined=c(DOD, Industry)
vars=c(Combined)
library(shiny)
ui <- fluidPage(fluidRow(style="padding-bottom: 20px;", column(5, selectInput('xcol', 'X Variable', vars)), column(5, 'ycol', 'Y Variable', vars, selected = vars[2])), column(4, numericInput('clusters', 'Cluster count', 3, min=20, max=1500))
), fluidRow(plotOutput('kmeans', height = 1500px))),
server <- function(input, output, session) { selectedData=reactive({dataset[, c(input$xcol, input$ycol)]}) clusters = reactive({kmeans(selectedData(), input$clusters)}) output$kmeans=renderPlot(height=1500, {res=clusters() par(mar=c(5.1, 4.1, 0,1)) plot(selectedData(), col=res$cluster, pch=20, cex=3), points(res$centers, pch=4, cex=4, lwd=4)})
}, options= list(height=1500))}
shinyApp(ui, server)
library("shiny", lib.loc="~/R/win-library/3.5")
detach("package:shiny", unload=TRUE)
ggplot(Industry.freq.df[1:20,], aes(x=word, y=frequency))+geom_bar(stat="identity", fill='darkred')+coord_flip()+theme_gdocs()+geom_text(aes(label=frequency), colour="white", hjust=1.25, size=5.0)
ggplot(myDict[1:20,], aes(x=word, y=frequency))+geom_bar(stat="identity", fill='darkred')+coord_flip()+theme_gdocs()+geom_text(aes(label=frequency), colour="white", hjust=1.25, size=5.0)
myDict.df<-as.data.frame(myDict)
myDict.df<-data.frame(myDict)
myDict.df<-data.frame(word=names(myDict))
ggplot(myDict[1:20,], aes(x=word, y=frequency))+geom_bar(stat="identity", fill='darkred')+coord_flip()+theme_gdocs()+geom_text(aes(label=frequency), colour="white", hjust=1.25, size=5.0)
myDict.df<-as.data.frame(myDict.df)
ggplot(myDict[1:20,], aes(x=word, y=frequency))+geom_bar(stat="identity", fill='darkred')+coord_flip()+theme_gdocs()+geom_text(aes(label=frequency), colour="white", hjust=1.25, size=5.0)
features_dod<-textstat_frequency(DOD_dfm, n=1200)
features_dod<-textstat_frequency(DOD_dict, n=1200)
features_dod$feature<-with(features_dod, reorder(feature, -frequency))
ggplot(features_dod, aes(x=feature, y=frequency)) + geom_point() + theme(axis.text.x =element_text(angel=90, hjust=1))
ggplot(features_dod, aes(x=feature, y=frequency)) + geom_point() + theme(axis.text.x =element_text(angle=90, hjust=1))
ggplot(data = DOD_dict, aes( x=document, y=Dictionary))
ggplot(DOD_dict, aes(x=document, y=Dictionary)) + geom_bar(stat="identity")+ labs(x="Document", y="Frequency", title = "Dictionary Across Documents")
ggplot(features_dod, aes(x=document, y=Dictionary)) + geom_bar(stat="identity")+ labs(x="Document", y="Frequency", title = "Dictionary Across Documents")
ggplot(features_dod, aes(x=feature, y=Dictionary)) + geom_bar(stat="identity")+ labs(x="feature", y="Frequency", title = "Dictionary Across Documents")
ggplot(features_dod, aes(x=feature, y=list)) + geom_bar(stat="identity")+ labs(x="feature", y="Frequency", title = "Dictionary Across Documents")
stem.corpus(Industry_dfm)
stem.corpus("tm_map", Industry_dfm)
> Industry_corpus2<-tm_map(Industry_corpus2, stemDocument, removeWords, stopwords("english"))
Industry_corpus2<-tm_map(Industry_corpus2, stemDocument, removeWords, stopwords("english"))
Industry_corpus<-tm_map(Industry_corpus, stemDocument, removeWords, stopwords("english"))
Industry_corpus2<-tm_map(Industry_corpus2, stemDocument)
Industry_corpus<-tm_map(Industry_corpus, stemDocument(Industry_corpus))
Industry_corpus <- tm_map(Industry_corpus, stemDocument, language = "english")
i.tdm<-TermDocumentMatrix(Industry_corpus, control = list(weighting=weightTf))
i.tdm<-TermDocumentMatrix(Industry_corpus)
i.tdm<-TermDocumentMatrix(Industry_corpus, control = list())
i.tdm<-TermDocumentMatrix(Industry_corpus, control = list())
tdm.Industry<-TermDocumentMatrix(Industry_corpus2, control = list())
Industry_corpus<- tm_map(Industry, stemDocument, language = "english")
tdm.Industry<-TermDocumentMatrix(Industry_corpus, control = list(weighting=weightTf(Industry_corpus)))
m.tdm.Industry<-TermDocumentMatrix(Industry_corpus, control = list(weighting=weightTf))
Industry_corpus<- tm_map(Industry_data, stemDocument, language = "english")
m.tdm.Industry<-TermDocumentMatrix(Industry_corpus, control = list(weighting=weightTf))
save.image("~/Project/industry cyber data/RR.RData")
savehistory("~/Project/industry cyber data/RR.Rhistory")
